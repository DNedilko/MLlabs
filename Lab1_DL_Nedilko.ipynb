{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEt+FaInlYrKbFh/M1K1F/"
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторна Робота 1\n",
        "## З дисципліни \"Методи глибинного навчання\" \n",
        "Тема: «Розробка  програмного  забезпечення  для  реалізації  двошарового \n",
        "персептрону з сигмоїдальною функцією активації»"
      ],
      "metadata": {
        "id": "q3iGO8Vs0oKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Частина 1***\n",
        "\n",
        "Завдання: розробити  програмне  забезпечення  для  реалізації  класичного \n",
        "нейрону (мову  програмування  студент  обирає  самостійно). Передбачити \n",
        "режим  навчання  класичного  нейрону  на  одному  навчальному  прикладі  та \n",
        "режим розпізнавання"
      ],
      "metadata": {
        "id": "R3oBMW9z2EAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Теоретичні відомості**\n",
        "\n",
        "Вхідними сигналами штучного нейрона x"
      ],
      "metadata": {
        "id": "hY0cuH2347pW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74V6bVSWwv05"
      },
      "outputs": [],
      "source": [
        "Вхідними "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PvhLrWtR6bce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "# зміні для початкового прикладу\n",
        "x0 = 1\n",
        "x1 = 3\n",
        "x2 = 5\n",
        "x3 = 7\n",
        "\n",
        "# label для початкового прикладу\n",
        "yr = 0.3\n",
        "# похибка\n",
        "dd = 0.1\n",
        "# ініціалізуємо вагові коефіціенти\n",
        "w0 = random.uniform(-1, 1)\n",
        "w1 = random.uniform(-1, 1)\n",
        "w2 = random.uniform(-1, 1)\n",
        "w3 = random.uniform(-1, 1)\n",
        "\n",
        "# лямда функції для кожного обчислення\n",
        "# активаційна функція\n",
        "y_cur_f = lambda x: 1/(1+math.exp(-x))\n",
        "# формула абсолютної похибки\n",
        "dn_f =lambda y : abs((yr-y)/yr)\n",
        "# обчслення значення похідної\n",
        "q_f = lambda y : y*(1-y)*(yr-y)\n",
        "\n",
        "i=0\n",
        "\n",
        "# нескінченний цикл, умовою виходу з якого - щоб похибка була допустима\n",
        "while True:\n",
        "    i+=1\n",
        "    # множимо відні дані на вагові коефіціенти\n",
        "    xs = x0*w0+x1*w1+x2*w2+x3*w3\n",
        "    # дізнаємося значення функції\n",
        "    y_cur =  y_cur_f(xs)\n",
        "    # визначаємо похибку\n",
        "    dn = dn_f(y_cur)\n",
        "    if dn <= dd:\n",
        "        # якщо похибка менше 10% - нейрон навчений, фінальні вагові коефіціенти відомі\n",
        "        print(f'echo({w0}, {w1}, {w2}, {w3})\\n'\n",
        "              f'Iterations {i}')\n",
        "        break\n",
        "\n",
        "\n",
        "    q = q_f(y_cur)\n",
        "# gradient descent\n",
        "    dw0 = x0*q\n",
        "    w0 += dw0\n",
        "    dw1 = x1 * q\n",
        "    w1 += dw1\n",
        "    dw2 = x2 * q\n",
        "    w2 += dw2\n",
        "    dw3 = x3 * q\n",
        "    w3 += dw3\n",
        "\n",
        "x0_r = 1.4\n",
        "x1_r = 2.89\n",
        "x2_r = 5.08\n",
        "x3_r = 6.6\n",
        "\n",
        "# тепер передбачаємо Y на інших даних\n",
        "xs_r = x0_r*w0+x1_r*w1+x2_r*w2+x3_r*w3\n",
        "yr_c = y_cur_f(xs_r)\n",
        "\n",
        "print(f'Ych = {yr_c}')"
      ],
      "metadata": {
        "id": "L1GydEX8w0Dt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}